==因为没有使用Maven管理项目，就没照着老师给的pdf中要求的提交格式交了==

==output文件夹中是输出文件，code文件夹中是代码文件（包括.java和.jar）==

# 0 运行流程介绍

## 0.1 数据集准备

先查看所有容器 `sudo docker ps`（获得容器id）

<img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241022213934691.png" alt="image-20241022213934691" style="zoom:50%;" />

将数据集传输到docker容器（h01）

`sudo docker cp <需要传输的文件路径> <容器id>:<传输文件在容器中的存放位置>`

<img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241022215634660.png" alt="image-20241022215634660" style="zoom: 67%;" />

将数据集放到hdfs上（需要先在hdfs新建一个input文件夹）然后在usr/local/hadoop目录下执行：

`./bin/hdfs dfs -put <数据集在docker中存放的位置> /input/`

可以通过`./bin/hdfs dfs -ls /input`查看是否放好了

<img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241022215703088.png" alt="image-20241022215703088" style="zoom:67%;" />

## 0.2 运行代码准备

同理，先把java代码文件放到docker（这里我直接放到了hadoop文件夹下）

<img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023003311613.png" alt="image-20241023003311613" style="zoom:67%;" />

然后生成相应的.class文件

```shell
javac -classpath `hadoop classpath` StockCount.java
```

再生成相应的.jar

```shell
jar -cvf stockcount.jar StockCount*.class
```

## 0.3 MapReduce运行

```shell
# 把结果保存到/output/<新建文件夹>
./bin/hadoop jar stockcount.jar StockCount /input/analyst_ratings.csv /output/<文件夹名>
# 查看
./bin/hadoop fs -ls /output/<文件夹名>
# 打印输出
./bin/hadoop fs -cat <输出文件的路径>
```

## 0.4 把docker中的文件传回

先在容器中运行以下命令，将文件从HDFS下载到容器的本地目录（代码文件不需要这步，输出文件需要）

`./bin/hdfs dfs -get /output/stock_count/part-r-00000 <需要在docker中存放的路径>`

再将该文件从 Docker 容器传输到本机

`docker cp <容器id>:<文件在docker中存放的位置> <文件在本机需要存储的位置>`

## 0.5 遇到错误

生成.java文件相应的.class文件时，遇到多次报错。

**错误1：**`StockCount.java:19: error: unmappable character for encoding ASCII            // ????????????????????????               ^`

原因：代码文件中包含非ASCII编码的字符，编译器默认使用 ASCII编码，无法识别这些字符。

解决方法：指定编码方式

```shell
javac -encoding UTF-8 -classpath `hadoop classpath`StockCount.java
```

**错误2：**`StockCount.java:2: error: package org.apache.hadoop.conf does not exist import org.apache.hadoop.conf.Configuration;                             ^`

原因：找不到 Hadoop的核心类库。

解决方法：

直接输入`/usr/local/hadoop/bin/hadoop classpath`，会得到输出hadoop的classpath，然后直接把它粘贴到命令行里即可，最终完整可用的命令如下

```shell
javac -encoding UTF-8 -classpath "/usr/local/hadoop/etc/hadoop:/usr/local/hadoop/share/hadoop/common/lib/*:/usr/local/hadoop/share/hadoop/common/*:/usr/local/hadoop/share/hadoop/hdfs:/usr/local/hadoop/share/hadoop/hdfs/lib/*:/usr/local/hadoop/share/hadoop/hdfs/*:/usr/local/hadoop/share/hadoop/mapreduce/*:/usr/local/hadoop/share/hadoop/yarn:/usr/local/hadoop/share/hadoop/yarn/lib/*:/usr/local/hadoop/share/hadoop/yarn/*" StockCount.java
```



# 1 StockCount

​	要求：在HDFS上加载上市公司热点新闻标题数据集（analyst_ratings.csv），该数据集收集了部分上市公司的热点财经新闻标题。编写MapReduce程序完成以下任务：统计数据集上市公司股票代码（“stock”列）的出现次数，按出现次数从大到小输出，输出格式为“<排名>：<股票代码>，<次数>”。

## 1.1 设计思路

​	最直观的想法是先将需要的股票代码（stock列）提取出来，维护一个含股票代码和出现次数两个字段的列表，对重复出现的股票代码进行次数累加。最后做排序和格式的修改。

* Mapper

  ​	定义一个StockMapper类，逐行处理数据，使用split方法切片，提取第四个字段stock，然后将每个股票代码视为出现了1次，输出键值对`<股票代码，1>`。

* Reducer

  ​	定义一个StockReducer类，接收来自Mapper的输出，累加相同股票代码的出现次数，得到每个股票代码的总出现次数；并维护一个列表存储每个股票代码及其出现次数。

  ​	对列表按照股票代码出现次数进行降序排序，遍历排序后的列表，为每个股票代码生成一个排名，并按照指定的格式输出结果。

*  main

  ​	设置MapReduce作业的配置：配置Mapper和Reducer类；指定输入、输出文件路径（args[0]和 args[1]）；启动作业并等待作业完成。

## 1.2 程序运行结果

* 终端输出结果

  运行MapReduce结果

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023004923458.png" alt="image-20241023004923458" style="zoom:67%;" />

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023004956867.png" alt="image-20241023004956867" style="zoom: 67%;" />

  打印输出文件结果

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023005039378.png" alt="image-20241023005039378" style="zoom:67%;" />

* WEB页面截图

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023005227206.png" alt="image-20241023005227206" style="zoom:67%;" />

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023005258600.png" alt="image-20241023005258600" style="zoom:67%;" />

## 1.3 程序分析

​	进一步对性能、扩展性等方面存在的不足和可能改进之处进行分析。

### 1.3.1 Mapper输出量

**不足：**对每一行（股票代码不为空的）数据都输出`<股票代码，1>`，导致Mapper输出量太大。

**改进分析：**先在Mapper对股票代码的计数进行局部聚合，减少Mapper和Reducer之间的数据传输量。

### 1.3.2 Reducer运行内存

**不足：**使用List来存储所有股票代码和它们的出现次数，并对整个List进行排序，这对于大型数据集来说会占用大量内存，可能导致崩溃。

**改进分析：**可以将数据分成多个部分进行排序，然后通过归并排序的方法将结果合并，降低内存占用。



# 2 WordFrequency

​	要求：在HDFS上加载上市公司热点新闻标题数据集（analyst_ratings.csv），该数据集收集了部分上市公司的热点财经新闻标题。统计数据集热点新闻标题（“headline”列）中出现的前100个高频单词，按出现次数从大到小输出。要求忽略大小写，忽略标点符号，忽略停词（stop-word-list.txt）。输出格式为“<排名 >：<单词>，<次数>”。

## 2.1 设计思路

​	设计的思路与前一个任务基本一致，但多了几个处理：停词表的加载、对切片后字段的处理，

* Mapper

  ​	将停词表加载到HashSet中，可以在后续操作快速查询是否为停词。

  ​	逐行处理数据，使用split方法切片，提取第二个字段headline；去除标点符号，将文本转换为小写，并按空格分割成单词；检查每个单词是否为停词或空词，如果不是，则将其输出为键值对 `<单词，1>` 。

* Reducer

  ​	接收来自Mapper的输出，累加相同单词的出现次数，得到每个单词的总出现次数；并维护一个map存储每个单词及其出现次数。

  ​	cleanup方法在Reducer任务结束后将map转换为list，按照单词出现次数进行降序排序，输出出现次数最多的前100个单词，格式为“<排名>: <单词>, <次数>”。

*  main

  ​	设置MapReduce作业的配置：配置Mapper和Reducer类；指定输入、输出文件路径（args[0]和 args[1]）；启动作业并等待作业完成。



## 2.2 程序运行结果

* 终端输出结果

  运行MapReduce结果

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023029884.png" alt="image-20241023023029884" style="zoom:67%;" />

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023051349.png" alt="image-20241023023051349" style="zoom:67%;" />

  打印输出文件结果

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023129595.png" alt="image-20241023023129595" style="zoom:67%;" />

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023147566.png" alt="image-20241023023147566" style="zoom:67%;" />

* WEB页面截图

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023238356.png" alt="image-20241023023238356" style="zoom:67%;" />

  <img src="C:\Users\华为\AppData\Roaming\Typora\typora-user-images\image-20241023023305937.png" alt="image-20241023023305937" style="zoom:67%;" />

## 2.3 程序分析

​	进一步对性能、扩展性等方面存在的不足和可能改进之处进行分析。

### 2.3.1 Reducer内存

**不足：**WordReducer将所有的单词计数存储在一个HashMap中。如果输入数据量非常大，单词的种类和数量超过Reducer的内存限制，会导致内存溢出问题。

**改进分析：**先在Mapper对单词的计数进行局部聚合，减少Mapper和Reducer之间的数据传输量，以此减少Reducer阶段需要处理的数据量，从而减轻内存压力。

### 2.3.2 排序优化

**不足**：在Reducer的cleanup方法中，对所有单词进行排序，性能开销较大，尤其当单词总量较大时，排序时间会显著增长。

**改进分析**：可以先找到出现次数第100大的元素，然后剔除比该元素出现次数少的单词，对最高频100个元素进行排序，减少了不必要的全局排序开销。
